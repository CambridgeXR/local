<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>360 VR Player (Cambridge XR)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no" />
  <meta name="theme-color" content="#000000"/>

  <style>
    html, body {
      margin: 0; padding: 0; height: 100%; background: #000; color: #fff;
      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, sans-serif;
      overscroll-behavior: contain;
      touch-action: manipulation;
    }
    canvas { display:block; width:100vw; height:100vh; }

    /* Minimal floating UI with smooth fade (5s idle) */
    #ui {
      position: fixed; inset: 0; display: grid; place-items: center; pointer-events: none;
      opacity: 1; transition: opacity 0.4s ease;
    }
    #ui.fade { opacity: 0; }
    #ui.hidden { display: none; } /* used only during VR */

    .panel {
      pointer-events: auto;
      display: grid; gap: 12px;
      width: min(92vw, 520px);
      text-align: center;
      background: transparent; border: none; box-shadow: none; backdrop-filter: none;
    }
    .btn {
      appearance: none; border: none; outline: none;
      padding: 14px 16px; border-radius: 12px; font-weight: 600; font-size: 1.05rem;
      background: #1a73e8; color: #fff; box-shadow: 0 6px 18px rgba(26,115,232,.35);
      cursor: pointer; transition: transform .06s ease, filter .2s ease, opacity .2s ease;
      width: 100%;
    }
    .btn.secondary { background: #2b2b2b; box-shadow: 0 6px 18px rgba(0,0,0,.35); }
    .btn:active { transform: translateY(1px) scale(.99); }
    .btn[disabled] { opacity: .5; cursor: not-allowed; }
    input[type=file] { display: none; }

    .brand {
      opacity: .7; font-size: 0.75rem; margin-top: 4px; font-style: italic;
      transition: opacity 0.4s ease;
    }
    .brand.hidden { opacity: 0; }

    #toast {
      position: fixed; bottom: 14px; left: 50%; transform: translateX(-50%);
      background: rgba(0,0,0,0.65); color: #fff; font-size: .95rem;
      padding: 10px 12px; border-radius: 10px; opacity: 0; transition: opacity .25s ease;
      pointer-events: none;
    }
    #toast.show { opacity: 1; }

    @media (prefers-reduced-motion: reduce) {
      #ui, .brand, #toast { transition: none; }
    }
  </style>
</head>
<body>

  <!-- Rendering surface -->
  <canvas id="glcanvas" aria-label="360 VR Canvas"></canvas>

  <!-- Hidden <video> used as the texture -->
  <video id="video360" playsinline webkit-playsinline preload="metadata" loop crossorigin="anonymous" style="display:none"></video>

  <!-- Minimal floating UI -->
  <div id="ui" aria-live="polite">
    <div class="panel">
      <button id="selectBtn" class="btn secondary" type="button">Select simulation</button>
      <input id="fileInput" type="file" accept="video/*" />
      <button id="vrBtn" class="btn" type="button" disabled>Enter VR</button>
      <div id="brandText" class="brand">Brought to you by Cambridge XR</div>
    </div>
  </div>

  <div id="toast" role="status" aria-live="polite"></div>

  <script>
  (() => {
    // ======== UI Helpers ========
    const HIDE_DELAY = 5000; // 5 seconds idle fade
    const ui = document.getElementById('ui');
    const toast = document.getElementById('toast');
    const brand = document.getElementById('brandText');
    let hideUITimer = null;

    function showToast(msg, ms = 1800) {
      toast.textContent = msg;
      toast.classList.add('show');
      clearTimeout(showToast._t);
      showToast._t = setTimeout(() => toast.classList.remove('show'), ms);
    }
    function scheduleUIHide() {
      clearTimeout(hideUITimer);
      hideUITimer = setTimeout(() => { ui.classList.add('fade'); }, HIDE_DELAY);
    }
    function showUI() {
      clearTimeout(hideUITimer);
      ui.classList.remove('hidden');
      void ui.offsetWidth; // reflow
      ui.classList.remove('fade');
      scheduleUIHide();
    }
    document.addEventListener('pointerdown', showUI, {passive:true});

    // ======== Video / File handling ========
    const fileInput = document.getElementById('fileInput');
    const selectBtn = document.getElementById('selectBtn');
    const vrBtn = document.getElementById('vrBtn');
    const video = document.getElementById('video360');
    let objectURL = null;

    selectBtn.addEventListener('click', () => fileInput.click());
    fileInput.addEventListener('change', async (ev) => {
      const file = ev.target.files && ev.target.files[0];
      if (!file) return;
      try {
        if (objectURL) URL.revokeObjectURL(objectURL);
        objectURL = URL.createObjectURL(file);
        video.src = objectURL;
        video.loop = true;
        video.playsInline = true;
        video.setAttribute('playsinline', '');
        video.setAttribute('webkit-playsinline', '');
        await ensureVideoPlays();
        vrBtn.disabled = false;
        showToast('Simulation loaded.');
        showUI();
      } catch (err) {
        console.error(err);
        showToast('Could not load video.');
      }
    });

    async function ensureVideoPlays() {
      try {
        video.muted = false;
        await video.play();
      } catch (e) {
        // Autoplay with sound may still require another tap depending on settings.
      }
    }

    // ======== Wake Lock & Motion permission ========
    let wakeLock = null;
    async function requestWakeLock() {
      try {
        if ('wakeLock' in navigator) {
          wakeLock = await navigator.wakeLock.request('screen');
        }
      } catch (e) {}
    }
    document.addEventListener('visibilitychange', async () => {
      if (wakeLock !== null && document.visibilityState === 'visible') {
        try { wakeLock = await navigator.wakeLock.request('screen'); } catch (e) {}
      }
    });
    async function requestMotionPermissionIfNeeded() {
      try {
        if (typeof DeviceMotionEvent !== 'undefined' &&
            typeof DeviceMotionEvent.requestPermission === 'function') {
          const resp = await DeviceMotionEvent.requestPermission();
          return resp === 'granted';
        }
      } catch (e) {}
      return true;
    }
    async function goFullscreen() {
      try {
        const el = document.documentElement;
        if (el.requestFullscreen) await el.requestFullscreen();
        else if (el.webkitRequestFullscreen) await el.webkitRequestFullscreen();
      } catch (e) {}
    }

    // ======== Minimal WebGL + WebXR 360 player (no external libs) ========
    const canvas = document.getElementById('glcanvas');
    let gl = canvas.getContext('webgl2', {alpha:false, antialias:true, xrCompatible:true});
    if (!gl) gl = canvas.getContext('webgl', {alpha:false, antialias:true});

    function resizeCanvas() {
      const dpr = Math.max(1, Math.min(2, window.devicePixelRatio || 1));
      const w = Math.floor(window.innerWidth * dpr);
      const h = Math.floor(window.innerHeight * dpr);
      if (canvas.width !== w || canvas.height !== h) {
        canvas.width = w; canvas.height = h;
      }
      gl.viewport(0, 0, canvas.width, canvas.height);
    }
    window.addEventListener('resize', resizeCanvas);
    resizeCanvas();

    // --- Shaders: sample equirect video on inside of a sphere ---
    const vsSrc = `
      attribute vec3 aPosition;
      attribute vec2 aUV;
      uniform mat4 uProj;
      uniform mat4 uView;
      uniform mat4 uModel;
      varying vec2 vUV;
      void main() {
        // Flip X to render inside the sphere without reversing culling
        vec4 pos = uModel * vec4(aPosition * vec3(-1.0, 1.0, 1.0), 1.0);
        gl_Position = uProj * uView * pos;
        vUV = vec2(1.0 - aUV.x, aUV.y);
      }
    `;
    const fsSrc = `
      precision mediump float;
      varying vec2 vUV;
      uniform sampler2D uTex;
      void main() {
        gl_FragColor = texture2D(uTex, vUV);
      }
    `;
    function compileShader(type, src) {
      const s = gl.createShader(type);
      gl.shaderSource(s, src);
      gl.compileShader(s);
      if (!gl.getShaderParameter(s, gl.COMPILE_STATUS)) {
        console.error(gl.getShaderInfoLog(s));
        gl.deleteShader(s);
        return null;
      }
      return s;
    }
    function createProgram(vs, fs) {
      const p = gl.createProgram();
      gl.attachShader(p, vs);
      gl.attachShader(p, fs);
      gl.linkProgram(p);
      if (!gl.getProgramParameter(p, gl.LINK_STATUS)) {
        console.error(gl.getProgramInfoLog(p));
        return null;
      }
      return p;
    }
    const prog = createProgram(compileShader(gl.VERTEX_SHADER, vsSrc), compileShader(gl.FRAGMENT_SHADER, fsSrc));
    gl.useProgram(prog);
    const loc = {
      aPosition: gl.getAttribLocation(prog, 'aPosition'),
      aUV: gl.getAttribLocation(prog, 'aUV'),
      uProj: gl.getUniformLocation(prog, 'uProj'),
      uView: gl.getUniformLocation(prog, 'uView'),
      uModel: gl.getUniformLocation(prog, 'uModel'),
      uTex: gl.getUniformLocation(prog, 'uTex'),
    };

    // --- Sphere geometry (radius=1, segments=64x64) ---
    function createSphere(segU=64, segV=64) {
      const verts = [], uvs = [], idx = [];
      for (let y=0; y<=segV; y++) {
        const v = y/segV;
        const phi = v * Math.PI; // 0..PI
        for (let x=0; x<=segU; x++) {
          const u = x/segU;
          const theta = u * Math.PI*2.0; // 0..2PI
          const sx = Math.sin(phi)*Math.cos(theta);
          const sy = Math.cos(phi);
          const sz = Math.sin(phi)*Math.sin(theta);
          verts.push(sx, sy, sz);
          uvs.push(u, v);
        }
      }
      for (let y=0; y<segV; y++) {
        for (let x=0; x<segU; x++) {
          const i = y*(segU+1)+x;
          const a=i, b=i+segU+1, c=i+1, d=i+segU+2;
          idx.push(a,b,c, c,b,d);
        }
      }
      return {verts:new Float32Array(verts), uvs:new Float32Array(uvs), idx:new Uint32Array(idx)};
    }
    const sphere = createSphere(64,64);

    const vboPos = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, vboPos);
    gl.bufferData(gl.ARRAY_BUFFER, sphere.verts, gl.STATIC_DRAW);
    gl.enableVertexAttribArray(loc.aPosition);
    gl.vertexAttribPointer(loc.aPosition, 3, gl.FLOAT, false, 0, 0);

    const vboUV = gl.createBuffer();
    gl.bindBuffer(gl.ARRAY_BUFFER, vboUV);
    gl.bufferData(gl.ARRAY_BUFFER, sphere.uvs, gl.STATIC_DRAW);
    gl.enableVertexAttribArray(loc.aUV);
    gl.vertexAttribPointer(loc.aUV, 2, gl.FLOAT, false, 0, 0);

    const ibo = gl.createBuffer();
    gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, ibo);
    gl.bufferData(gl.ELEMENT_ARRAY_BUFFER, sphere.idx, gl.STATIC_DRAW);

    // Model matrix: scale sphere large (user at origin inside)
    function mat4Identity() { return new Float32Array([1,0,0,0, 0,1,0,0, 0,0,1,0, 0,0,0,1]); }
    function mat4Scale(sx,sy,sz) { const m=mat4Identity(); m[0]=sx; m[5]=sy; m[10]=sz; return m; }
    const modelMatrix = mat4Scale(5000,5000,5000); // big sphere

    // Texture from <video>
    const tex = gl.createTexture();
    gl.bindTexture(gl.TEXTURE_2D, tex);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.LINEAR);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
    gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
    gl.uniform1i(loc.uTex, 0);

    function updateVideoTexture() {
      if (video.readyState >= 2 && !video.paused) {
        try {
          gl.bindTexture(gl.TEXTURE_2D, tex);
          gl.pixelStorei(gl.UNPACK_FLIP_Y_WEBGL, false);
          gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, gl.RGBA, gl.UNSIGNED_BYTE, video);
        } catch (e) {
          // Some devices need texSubImage2D after initial allocation; fallback:
          try {
            gl.texSubImage2D(gl.TEXTURE_2D,0,0,0,gl.RGBA,gl.UNSIGNED_BYTE,video);
          } catch (e2) {}
        }
      }
    }

    // Basic perspective for non-XR fallback
    function perspective(out, fovy, aspect, near, far){
      const f=1.0/Math.tan(fovy/2), nf=1/(near-far);
      out[0]=f/aspect; out[1]=0; out[2]=0; out[3]=0;
      out[4]=0; out[5]=f; out[6]=0; out[7]=0;
      out[8]=0; out[9]=0; out[10]=(far+near)*nf; out[11]=-1;
      out[12]=0; out[13]=0; out[14]=2*far*near*nf; out[15]=0;
      return out;
    }
    function mat4Invert(out, a) {
      // general 4x4 inverse (adapted minimal)
      const m = a, b = new Float32Array(16);
      b[0] = m[5]*m[10]*m[15]-m[5]*m[11]*m[14]-m[9]*m[6]*m[15]+m[9]*m[7]*m[14]+m[13]*m[6]*m[11]-m[13]*m[7]*m[10];
      b[4] = -m[4]*m[10]*m[15]+m[4]*m[11]*m[14]+m[8]*m[6]*m[15]-m[8]*m[7]*m[14]-m[12]*m[6]*m[11]+m[12]*m[7]*m[10];
      b[8] = m[4]*m[9]*m[15]-m[4]*m[11]*m[13]-m[8]*m[5]*m[15]+m[8]*m[7]*m[13]+m[12]*m[5]*m[11]-m[12]*m[7]*m[9];
      b[12]= -m[4]*m[9]*m[14]+m[4]*m[10]*m[13]+m[8]*m[5]*m[14]-m[8]*m[6]*m[13]-m[12]*m[5]*m[10]+m[12]*m[6]*m[9];
      b[1] = -m[1]*m[10]*m[15]+m[1]*m[11]*m[14]+m[9]*m[2]*m[15]-m[9]*m[3]*m[14]-m[13]*m[2]*m[11]+m[13]*m[3]*m[10];
      b[5] = m[0]*m[10]*m[15]-m[0]*m[11]*m[14]-m[8]*m[2]*m[15]+m[8]*m[3]*m[14]+m[12]*m[2]*m[11]-m[12]*m[3]*m[10];
      b[9] = -m[0]*m[9]*m[15]+m[0]*m[11]*m[13]+m[8]*m[1]*m[15]-m[8]*m[3]*m[13]-m[12]*m[1]*m[11]+m[12]*m[3]*m[9];
      b[13]= m[0]*m[9]*m[14]-m[0]*m[10]*m[13]-m[8]*m[1]*m[14]+m[8]*m[2]*m[13]+m[12]*m[1]*m[10]-m[12]*m[2]*m[9];
      b[2] = m[1]*m[6]*m[15]-m[1]*m[7]*m[14]-m[5]*m[2]*m[15]+m[5]*m[3]*m[14]+m[13]*m[2]*m[7]-m[13]*m[3]*m[6];
      b[6] = -m[0]*m[6]*m[15]+m[0]*m[7]*m[14]+m[4]*m[2]*m[15]-m[4]*m[3]*m[14]-m[12]*m[2]*m[7]+m[12]*m[3]*m[6];
      b[10]= m[0]*m[5]*m[15]-m[0]*m[7]*m[13]-m[4]*m[1]*m[15]+m[4]*m[3]*m[13]+m[12]*m[1]*m[7]-m[12]*m[3]*m[5];
      b[14]= -m[0]*m[5]*m[14]+m[0]*m[6]*m[13]+m[4]*m[1]*m[14]-m[4]*m[2]*m[13]-m[12]*m[1]*m[6]+m[12]*m[2]*m[5];
      b[3] = -m[1]*m[6]*m[11]+m[1]*m[7]*m[10]+m[5]*m[2]*m[11]-m[5]*m[3]*m[10]-m[9]*m[2]*m[7]+m[9]*m[3]*m[6];
      b[7] = m[0]*m[6]*m[11]-m[0]*m[7]*m[10]-m[4]*m[2]*m[11]+m[4]*m[3]*m[10]+m[8]*m[2]*m[7]-m[8]*m[3]*m[6];
      b[11]= -m[0]*m[5]*m[11]+m[0]*m[7]*m[9]+m[4]*m[1]*m[11]-m[4]*m[3]*m[9]-m[8]*m[1]*m[7]+m[8]*m[3]*m[5];
      b[15]= m[0]*m[5]*m[10]-m[0]*m[6]*m[9]-m[4]*m[1]*m[10]+m[4]*m[2]*m[9]+m[8]*m[1]*m[6]-m[8]*m[2]*m[5];
      let det = m[0]*b[0] + m[1]*b[4] + m[2]*b[8] + m[3]*b[12];
      if (!det) { out.set(mat4Identity()); return out; }
      det = 1.0/det; for (let i=0;i<16;i++) out[i]=b[i]*det; return out;
    }

    // Fallback view rotation via DeviceOrientation (monoscopic)
    let fallbackYaw=0, fallbackPitch=0;
    window.addEventListener('deviceorientation', (e) => {
      if (e.alpha!=null && e.beta!=null && e.gamma!=null) {
        // Simple estimate: yaw from alpha, pitch from beta (not perfect, but usable)
        fallbackYaw = (e.alpha || 0) * Math.PI/180;
        fallbackPitch = ((e.beta || 0) - 90) * Math.PI/180;
      }
    });

    function mat4FromYawPitch(out, yaw, pitch){
      const cy=Math.cos(yaw), sy=Math.sin(yaw);
      const cp=Math.cos(pitch), sp=Math.sin(pitch);
      // R = Ry * Rx
      out.set([ cy, sy*sp, sy*cp, 0,
               0,   cp,    -sp,   0,
               -sy, cy*sp, cy*cp, 0,
               0,   0,      0,    1 ]);
      // invert rotation (view matrix)
      return mat4Invert(out, out);
    }

    // --- Render loop (non-XR) ---
    const projFallback = new Float32Array(16);
    function renderFallback() {
      resizeCanvas();
      gl.clearColor(0,0,0,1);
      gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
      gl.disable(gl.CULL_FACE); gl.disable(gl.DEPTH_TEST);
      updateVideoTexture();

      // Projection
      perspective(projFallback, Math.PI/2.0, canvas.width/canvas.height, 0.1, 10000.0);
      gl.uniformMatrix4fv(loc.uProj, false, projFallback);

      // View from device orientation
      const view = new Float32Array(16);
      mat4FromYawPitch(view, fallbackYaw, fallbackPitch);
      gl.uniformMatrix4fv(loc.uView, false, view);

      gl.uniformMatrix4fv(loc.uModel, false, modelMatrix);
      gl.drawElements(gl.TRIANGLES, sphere.idx.length, gl.UNSIGNED_INT, 0);
      requestAnimationFrame(renderFallback);
    }

    // ======== WebXR VR ========
    let xrSession = null, xrRefSpace = null;

    async function enterVR() {
      if (!navigator.xr) throw new Error('WebXR not supported');
      if (!gl.makeXRCompatible) throw new Error('XR incompatible context');

      await requestMotionPermissionIfNeeded();
      await goFullscreen();
      await requestWakeLock();
      await ensureVideoPlays();

      brand.classList.add('hidden');
      // fade UI then hide for VR
      await new Promise((resolve) => {
        const done = () => { ui.classList.add('hidden'); ui.removeEventListener('transitionend', done); resolve(); };
        ui.classList.add('fade');
        if (getComputedStyle(ui).transitionDuration !== '0s') {
          ui.addEventListener('transitionend', done, {once:true});
        } else { done(); }
      });

      xrSession = await navigator.xr.requestSession('immersive-vr', { requiredFeatures: ['local-floor'] });
      await gl.makeXRCompatible();
      xrSession.updateRenderState({ baseLayer: new XRWebGLLayer(xrSession, gl) });
      xrRefSpace = await xrSession.requestReferenceSpace('local-floor');

      xrSession.addEventListener('end', onXREnded);

      const onXRFrame = (t, frame) => {
        const session = frame.session;
        const pose = frame.getViewerPose(xrRefSpace);
        if (!pose) { session.requestAnimationFrame(onXRFrame); return; }

        updateVideoTexture();
        gl.bindFramebuffer(gl.FRAMEBUFFER, session.renderState.baseLayer.framebuffer);
        gl.clearColor(0,0,0,1);
        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);
        gl.useProgram(prog);
        gl.uniformMatrix4fv(loc.uModel, false, modelMatrix);
        gl.disable(gl.CULL_FACE); gl.disable(gl.DEPTH_TEST);

        for (const view of pose.views) {
          const viewport = session.renderState.baseLayer.getViewport(view);
          gl.viewport(viewport.x, viewport.y, viewport.width, viewport.height);

          // Projection from XR
          gl.uniformMatrix4fv(loc.uProj, false, view.projectionMatrix);

          // View = inverse of view transform
          const viewMat = new Float32Array(16);
          // XRView.transform is the view transform (camera to world),
          // so we invert to get world->camera (view matrix).
          mat4Invert(viewMat, view.transform.matrix);
          gl.uniformMatrix4fv(loc.uView, false, viewMat);

          gl.drawElements(gl.TRIANGLES, sphere.idx.length, gl.UNSIGNED_INT, 0);
        }
        session.requestAnimationFrame(onXRFrame);
      };
      xrSession.requestAnimationFrame(onXRFrame);
    }

    function onXREnded() {
      xrSession = null; xrRefSpace = null;
      // Bring UI back smoothly
      brand.classList.remove('hidden');
      ui.classList.remove('hidden');
      void ui.offsetWidth;
      ui.classList.remove('fade');
      scheduleUIHide();
      showToast('Exited VR.');
      // Resume fallback preview rendering
      requestAnimationFrame(renderFallback);
    }

    // Hook up VR button
    vrBtn.addEventListener('click', async () => {
      try {
        if (!navigator.xr) throw new Error('WebXR not supported on this device/browser.');
        await enterVR();
        showToast('Entering VR…', 1200);
      } catch (e) {
        console.error(e);
        // Fall back to monoscopic preview only
        brand.classList.remove('hidden');
        ui.classList.remove('hidden');
        void ui.offsetWidth;
        ui.classList.remove('fade');
        scheduleUIHide();
        showToast('VR not available on this device/browser.');
      }
    });

    // Start monoscopic preview loop
    requestAnimationFrame(renderFallback);
    scheduleUIHide();
  })();
  </script>
</body>
</html>
